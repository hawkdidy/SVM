\documentclass[11pt,oneside,a4paper]{article}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{lscape}
\usepackage{psfrag}
\usepackage[usenames]{color}
\usepackage{bbm}
\usepackage[update]{epstopdf}
\usepackage[bookmarks,pdfstartview=FitH,a4paper,pdfborder={0 0 0}]{hyperref}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{course}
\usepackage{fancyhdr}
\usepackage{multirow}
\pagestyle{fancy}
\usepackage{tikz}
\usepackage{subcaption} 
\usepackage{float}


\renewcommand{\sectionmark}[1]{\markboth{#1}{#1}}
\renewcommand{\subsectionmark}[1]{\markright{#1}}

\fancyhf{}
\fancyhead[RO]{\nouppercase{\footnotesize\sc\leftmark\ \hrulefill\ \thepage}}
\fancyhead[RE]{\nouppercase{\footnotesize\sc\thepage\ \hrulefill\ }}
\renewcommand{\headrulewidth}{0pt}

\makeatletter
\def\cleardoublepage{\clearpage\if@twoside \ifodd\c@page\else%
\hbox{}%
\thispagestyle{empty}%
\clearpage%
\if@twocolumn\hbox{}\clearpage\fi\fi\fi}
\makeatother


\renewcommand{\topfraction}{0.9}  % max fraction of floats at top
\renewcommand{\bottomfraction}{0.8} % max fraction of floats at bottom
% Parameters for TEXT pages (not float pages):
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}            % 2 may work better
\setcounter{dbltopnumber}{2}           % for 2-column pages
\renewcommand{\dbltopfraction}{0.9}    % fit big float above 2-col. text
\renewcommand{\textfraction}{0.07}     % allow minimal text w. figs
% Parameters for FLOAT pages (not text pages):
\renewcommand{\floatpagefraction}{0.7}  % require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\renewcommand{\dblfloatpagefraction}{0.7} % require fuller float pages

\sloppy

\widowpenalty=10000
\clubpenalty=10000

\edef\today{%\number\day\
\ifcase\month\or
January\or February\or March\or April\or May\or June\or July\or
August\or September\or October\or November\or December\fi\ \number\year}
\title{\vspace*{40.0mm}
  \bf\sf Support Vector Machine Assignment 
         \vspace*{20.0mm} \\
  \vspace*{40.0mm}
  %\vspace{-20mm}\framebox{DRAFT VERSION}\vspace{20mm} \\
  }
\author{\sf Mohamedhakim Elakhrass}
\date{\sf 15/07/2016}




\begin{document}

	
	
\begin{figure}
  \parbox[t]{125mm}{
    \vspace*{6mm}
    \scriptsize\sf           FACULTY OF BIOSCIENCE ENGINEERING\\
    \scriptsize\sf           Masters of Bioinformatics \\
    \scriptsize\sf\bfseries  Support Vector Machines \\}
  \parbox[t]{40mm}{
    \begin{flushright}
      \includegraphics[height=15mm]{logo.eps}
    \end{flushright}}
\end{figure}

\maketitle
\thispagestyle{empty}
\raggedbottom

\cleardoublepage
\pagenumbering{roman}
\setcounter{tocdepth}{2}
\tableofcontents
\cleardoublepage
\pagenumbering{arabic}

\cleardoublepage

\section{Objectives}
The objectives of this assignment are to learn and work with real life applications of SVM. 
\section{Simple 2 Gaussian}
This sections looks at two simulated datasets. The datasets are created using the MatLab $randn()$ function. One dataset is centered around (1,1) and the other (-1,1)\\

\begin{figure}[H]
	\setbox0\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/2_Gaussians}%
	}%
	\setbox2\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/2_Gaussians_with_classifier}%
	}%
	\ifdim\ht0>\ht2
	\setbox0\hbox{%
		\includegraphics[height=\ht2]{../Figures/2_Gaussians}%
	}%
	\else
	\setbox2\hbox{%
		\includegraphics[height=\ht0]{../Figures/2_Gaussians_with_classifier}%
	}%
	\fi
	\noindent
	\parbox{.45\textwidth}{%
		\centering
		\unhbox0
		\caption{Two Simulated Datasets.}
	}%
	\hfil
	\parbox{.45\textwidth}{%
		\centering
		\unhbox2
		\caption{Two Simulated Datasets with Optimal Classifier.}
	}%
\end{figure}




\textbf{Given this figure, can you make a geometric construction using lines to estimate the optimal classifier? Under which conditions do you think this construction is optimal/valid?}\\

Figure 1:a is the output of the simulated datasets. As shown in figure 1:b it is possible to show an optimal classifier. This classifier is known as the Bayes Classifier. A test observation is assigned with predictor vector $x_{0}$ to the class j for which    \[ Pr(Y=j|X=x_{0}) \] is largest. The classifier is optimal because it produces the lowest possible error rate and allows for some overlap. The classifier is valid because the underlying distribution of the dataset is known. This falls into the special case $\Sigma_{xx1} = \Sigma_{xx2} - \Sigma_{xx}$, the covariance matrices are equal and the decision boundary is linear.
\section{The Support Vector Machine}

This section will deal with an online demo of a linear and none linear SVM. It will be used to learn the intuition behind changing SVM parameters and changes in the dataset.\\


\begin{figure}[H]
	\setbox0\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/Default_Linear_Kernal}%
	}%
	\setbox2\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/10_point_linear_Kernal}%
	}%
	\ifdim\ht0>\ht2
	\setbox0\hbox{%
		\includegraphics[height=\ht2]{../Figures/Default_Linear_Kernal}%
	}%
	\else
	\setbox2\hbox{%
		\includegraphics[height=\ht0]{../Figures/10_point_linear_Kernal}%
	}%
	\fi
	\noindent
	\parbox{.45\textwidth}{%
		\centering
		\unhbox0
		\caption{Default Linear Kernal.}
	}%
	\hfil
	\parbox{.45\textwidth}{%
		\centering
		\unhbox2
		\caption{10 Data Point Linear Kernal.}
	}%
\end{figure}

\textbf{Adjust the existing datasets to have at least 10 data points for each class. What do you observe when you are adding data points to the classes? How drastically can classification boundaries change.}

Data points added inside the margin drastically change the decision boundary  and become support vectors. Data points added to the side of the opposing color are also automatically support vectors but remain misclassified. Data points added to the same side as its own color have very little effect on the decision boundary, although the closer to the boundary the larger the effect. 

\textbf{What if you add an outlying datapoint which lies on the wrong side of the classification boundary? How does it affect the classification hyperplane?}

\begin{figure}[H]
	 \centering
	\includegraphics[scale=0.5]{../Figures/misclassified_linear_kernal}
	\caption{Outlier data point}
\end{figure}

A data point added to the wrong side of the boundary changes the direction of the hyperplane towards that point. If too many points are added the classifier misclassified all points of the opposing class. 

\textbf{Try different values of C regularization hyperparameter. How does it affect the classification outcome? What is the role of it?}\\
Using the intial dataset the effects of the regularization hyperparemter can be seen. The parameter control the slack of the SVM model. When C is high there is less tolerance for misclassification and therefore a smaller margin. When C is large there is higher tolerance for misclassification and a larger margin.

\begin{figure}[H]
	\setbox0\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/small_C_linear_Kernal}%
	}%
	\setbox2\hbox{%
		\includegraphics[width=.45\textwidth]{../Figures/large_C_linear_kernal}%
	}%
	\ifdim\ht0>\ht2
	\setbox0\hbox{%
		\includegraphics[height= \ht2]{../Figures/small_C_linear_Kernal}%
	}%
	\else
	\setbox2\hbox{%
		\includegraphics[height=\ht0]{../Figures/large_C_linear_kernal}%
	}%
	\fi
	\noindent
	\parbox{.45\textwidth}{%
		\centering
		\unhbox0
		\caption{C = .079}
		\label{fg:methods}
	}%
	\hfil
	\parbox{.45\textwidth}{%
		\centering
		\unhbox2
		\caption{C = 79}
		\label{fg:method_detail}
	}%
\end{figure}

 

 \begin{figure}[H]
 	\centering
 	\begin{subfigure}[b]{.5\textwidth}
 	
 		\textbf{Follow the instructions and switch back to RBF kernel by toggling the “k” button. Compare to the classification outcome of the linear case.Try to change the RBF kernel sigma hyper parameter. What is your intuition? How does it affect the classification boundaries? Now try to change both hyper parameters. What is the right choice of those if your data is almost linearly separable?}\\
 		
		 The default RBF kernal has no misclassification as opposed to the linear classifier. This is because the data set is not linearly separable, therefore the linear classifier performs poorly. The RBF kernal has the ability to wrap around the data. Small values of  $\sigma$ however will lead to a risk of over fitting and generalize well. Misclassification is only seen at the higher end of  $\sigma$. The higher  $\sigma$  is the more linear the decision boundary. \\
		 
		 The right choice to make when the data is almost linear separable is the linear kernel. As stated above, data that is almost linearly separable but has some overlap can be best classified using Bayes Optimal classifier. This will lead to a linear decision boundary with some misclassification. If an RBF kernel is chosen you may have good predictions on your validation data but the model will not generalize to the test data. Using the RBF kernal you can get a near linear decision boundary with $ c = 79$ and $\sigma = 10$
		 
 		
 	
 	\end{subfigure}%
 	\begin{subfigure}{.5\textwidth}
 		\vspace{-185pt}
 		\centering
 		\includegraphics[width=0.9\linewidth]{../Figures/Default_RBF}
 	\end{subfigure}
 \end{figure}
\begin{figure}[H]
	\centering
 		\includegraphics[scale=0.5]{../Figures/RBF_sigma_10_C_079}
 		\caption{Value of $\sigma = 0.79$}
\end{figure}
 \begin{figure}[H]
 	\centering
 	\begin{subfigure}{.25\textwidth}
 		\centering
 		\includegraphics[width=0.9\linewidth]{../Figures/RBF_sigma_0050}
 		\caption{Value of $\sigma = 0.050$}
 	\end{subfigure}%
 	\begin{subfigure}{.25\textwidth}
 		\centering
 		\includegraphics[width=0.9\linewidth]{../Figures/RBF_sigma_79}
 		\caption{Value of $\sigma = 0.79$}
 	\end{subfigure}%
 	\begin{subfigure}{.25\textwidth}
 		\centering
 		\includegraphics[width=0.9\linewidth]{../Figures/RBF_sigma_1}
 		\caption{Value of $\sigma = 1$}
 	\end{subfigure}%
 	\begin{subfigure}{.25\textwidth}
 		\centering
		\includegraphics[width=0.9\linewidth]{../Figures/RBF_sigma_16}
 		\caption{Value of $\sigma = 16$}
 	\end{subfigure}
 	\caption{How $\sigma$ effects RBF classifier with C = 1.0}
 \end{figure}
 
 \begin{figure}[H]
 	\centering
 	\begin{subfigure}[b]{.5\textwidth}
 		
 	\textbf{Create a linearly non-separable dataset with an overlapping region between classes (e.g. similar to the previous Gaussian clouds). Give comments on the role of the chosen kernel, the regularization parameter (C) and the kernel parameter (sigma)}\\
 	
 		For this set 25 red and 25 green points were created. These points were made to create a dataset as described above. An RBF kernel was chosen because the dataset is not linearly separable so using a linear kernel would be impossible. The parameters were chosen to appropriately classify the data points but also to leave some slack for misclassification. Due to the overlapping regions, if everything was perfectly classified on this validation set you would most likely see an over fitting when you introduce your test set. The C and sigma values were adjusted accordingly. The C value was chosen relatively high to allow for the misclassification. The Sigma is relatively small because a large sigma would cause a near linear decision boundary which would be useless in this case. 
 		
 		
 		
 	\end{subfigure}%
 	\begin{subfigure}{.5\textwidth}
 		\vspace{-185pt}
 		\centering
 		\includegraphics[width=0.9\linewidth]{../Figures/RBF_non_linear_data}
 	\end{subfigure}
 \end{figure}

\textbf{What is the role of Support Vectors? Change the data-sets to make the number of support vectors
increase/decrease. When does a particular datapoint become a Support Vector?}\\
	As a property of this being a quadratic programming problem that is  a dual problem many resulting values of $ \alpha_{k}$ are equal to zero in the classifier $ y(x)= sign[\sum_{k = 1}^{\#SV} \alpha_{k} y_{k} x_{k}^{T}x + b] $ This is a property called sparseness. The sum is of the none zero $\alpha_{k}$ which are now support vectors. Geometrically they are located close to the decision boundary. In a linear kernel all vectors inside or at the edge of the margin are support vectors as well as misclassified data points. For the RBF kernel $x$ is replaced by $\varphi(x)$. However this can be infinite dimensional. Therefore the problem can only be solved in the dual. 
	
\textbf{When does the corresponding importance of a Support Vector change?}\\
The importance of support vector changes when the influence it has on the decision boundary is altered. This can happen when changing the c parameter.

\section{Using LSSVM}
In this section the matlab package LSSVM will be used to explore the Iris Dataset.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{../Figures/iris_intial}
	\caption{Value of $\sigma = 0.79$}
\end{figure}

\textbf{What is the performance on the test set Xt and Yt?}\\
The performance shows a $55\%$ error rate.

\textbf{What happens when you are changing the degree of a polynomial kernel? Explain the obtained results.
Does it correspond to the changes in sigma hyperparameter of the RBF kernel in the previous example?}\\\

The first degree polynomial is just a linear kernel, therefore it has the same results. The 2nd degree has 4 misclassification. The 3rd degree has 3 misclassification. The 4th degree has 3 and the 5th has 3. Increasing the degree of polynomial is a little like decreasing sigma of the RBF. It creates a less linear boundary that is more prone to over fitting. 

\begin{figure}[H]
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{../Figures/poly_degree_1}
		\caption{Degree 1}
	\end{subfigure}
	%
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{../Figures/poly_degree_2}
		\caption{Degree 2}
	\end{subfigure}
	%
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{../Figures/poly_degree_3}
		\caption{Degree 3}
	\end{subfigure}
	%
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{../Figures/poly_degree_4}
		\caption{Degree 4}
	\end{subfigure}
	%
	\begin{subfigure}[b]{0.4\textwidth}
	\includegraphics[width=\textwidth]{../Figures/poly_degree_5}
	\caption{Degree 5}
\end{subfigure}
\caption{Varying Degrees of the Polynomial Kernel}
\end{figure}
\textbf{Try out a good range of
different sig2’s as kernel parameters. For each individual value of sig2, the corresponding LS-SVM
is evaluated on the test set. Make a figure of the sig2’s with their corresponding test set performance. Fix a reasonable choice for the sig2 of the RBF
kernel and again compare a range of gam’s by plotting the corresponding test set performances. What
is a good range for gam?}\\
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{../Figures/RBF_sig2}
	\caption{Error rate VS. Sig2}
\end{figure}
A range used for both sig2 and gamma was 0.01, 0.5, 4, 10, 20, 100.Between point 5 and 14 seem to have the best range for sig2. With a sig2 of 12 the best gam is between 2 and 8.   
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{../Figures/RBF_gam}
	\caption{Error rate VS. gam}
\end{figure}

Comparing to the results from the sample script you get a very similar outlook. You need a good balance between gam and sig to balance between over fitting and misclassification. 

\section{Choice of Hyper-parameters}
In this section the intuition developed from the previous sections will be used to start using autotuning algorithms. \\

\textbf{Motivate why this validation set used to optimize a number of(tuning-) parameters cannot used again to measure the final model.} \\

Validation set is used to optimize parameters to make sure that the model can generalize well. If someone was to just train the model on one data set and validate it on another without using a test set the model will likely "memorize the data" (difference between 'dumb' AI and smart 'AI'). Therefore a set of data that was not touched during the tuning process must be the final test to see if the model can generalize. 
\end{document}